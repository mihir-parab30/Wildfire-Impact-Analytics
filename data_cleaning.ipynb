{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install missing libraries (if not already installed)\n",
        "!pip install plotly seaborn --quiet\n",
        "\n",
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure plots are displayed properly in Colab\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"✅ Libraries successfully installed and imported!\")"
      ],
      "metadata": {
        "id": "jpR0YiSHvH1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa1d042-98bb-4c99-9495-6999c20b03b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Libraries successfully installed and imported!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kWLzQgkOa6p",
        "outputId": "78382b73-ccbe-4d3a-fe21-6ee7ac18ba7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scatter Plot"
      ],
      "metadata": {
        "id": "y4TczunzY9u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the wildfire dataset\n",
        "wildfire_df = pd.read_csv(\"expanded-usa-wildfire-dataset.csv\")\n",
        "\n",
        "# Extract year from the date column if available\n",
        "if \"DISCOVERY_DATE\" in wildfire_df.columns:\n",
        "    wildfire_df[\"Year\"] = pd.to_datetime(wildfire_df[\"DISCOVERY_DATE\"]).dt.year\n",
        "elif \"FIRE_YEAR\" in wildfire_df.columns:\n",
        "    wildfire_df[\"Year\"] = wildfire_df[\"FIRE_YEAR\"]\n",
        "else:\n",
        "    raise ValueError(\"No valid date column found in wildfire dataset.\")\n",
        "\n",
        "# Aggregate wildfire data by year (counting number of fires)\n",
        "wildfire_summary = wildfire_df.groupby(\"Year\").size().reset_index(name=\"Wildfire_Count\")\n",
        "\n",
        "# Load the AQI dataset\n",
        "aqi_df = pd.read_csv(\"pollution_2000_2023.csv\")\n",
        "\n",
        "# Select AQI columns and compute the max AQI per year\n",
        "aqi_columns = [\"O3 AQI\", \"CO AQI\", \"SO2 AQI\", \"NO2 AQI\"]\n",
        "\n",
        "# Extract year if needed\n",
        "if \"Date\" in aqi_df.columns:\n",
        "    aqi_df[\"Year\"] = pd.to_datetime(aqi_df[\"Date\"]).dt.year\n",
        "elif \"Year\" not in aqi_df.columns:\n",
        "    raise ValueError(\"No valid date column found in AQI dataset.\")\n",
        "\n",
        "# Compute the max AQI for each year\n",
        "aqi_summary = aqi_df.groupby(\"Year\")[aqi_columns].max().reset_index()\n",
        "\n",
        "# Create an \"Overall AQI\" column (max AQI from all pollutants)\n",
        "aqi_summary[\"Overall_AQI\"] = aqi_summary[aqi_columns].max(axis=1)\n",
        "\n",
        "# Merge wildfire and AQI datasets\n",
        "merged_df = pd.merge(wildfire_summary, aqi_summary[[\"Year\", \"Overall_AQI\"]], on=\"Year\", how=\"inner\")\n",
        "\n",
        "# Save the processed data to CSV\n",
        "merged_df.to_csv(\"wildfire_vs_aqi.csv\", index=False)\n",
        "\n",
        "print(\"CSV file saved as wildfire_vs_aqi.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTGKnfMSY31q",
        "outputId": "3809b05a-2199-4bd0-d739-d4e437a45129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file saved as wildfire_vs_aqi.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bubble Chart"
      ],
      "metadata": {
        "id": "JRBnT1gnY2JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the wildfire dataset\n",
        "wildfire_data_path = \"/content/expanded-usa-wildfire-dataset.csv\"\n",
        "wildfire_df = pd.read_csv(wildfire_data_path)\n",
        "\n",
        "# Define fire size classification\n",
        "fire_size_classes = {\n",
        "    \"A\": (0, 0.25),\n",
        "    \"B\": (0.26, 9.9),\n",
        "    \"C\": (10, 99.9),\n",
        "    \"D\": (100, 299.9),\n",
        "    \"E\": (300, 999.9),\n",
        "    \"F\": (1000, 4999.9),\n",
        "    \"G\": (5000, float(\"inf\"))\n",
        "}\n",
        "\n",
        "# Function to classify fire size\n",
        "def classify_fire_size(size):\n",
        "    for category, (min_size, max_size) in fire_size_classes.items():\n",
        "        if min_size <= size <= max_size:\n",
        "            return category\n",
        "    return \"Unknown\"\n",
        "\n",
        "# Apply classification to the dataset\n",
        "wildfire_df[\"Fire_Size_Class\"] = wildfire_df[\"FIRE_SIZE\"].apply(classify_fire_size)\n",
        "\n",
        "# Count the number of wildfires per size class\n",
        "fire_size_distribution = wildfire_df[\"Fire_Size_Class\"].value_counts().reset_index()\n",
        "fire_size_distribution.columns = [\"Fire Size Class\", \"Wildfire Count\"]\n",
        "\n",
        "# Save cleaned data to a new CSV file\n",
        "cleaned_file_path = \"cleaned_wildfire_Bubble_data.csv\"\n",
        "wildfire_df.to_csv(cleaned_file_path, index=False)\n",
        "\n",
        "print(f\"Processed data saved successfully: {cleaned_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVAp7XXoVMDs",
        "outputId": "18eeced1-4c68-47d3-eae6-6c179aec9454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data saved successfully: cleaned_wildfire_Bubble_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the AQI dataset\n",
        "aqi_df = pd.read_csv(\"pollution_2000_2023.csv\")\n",
        "\n",
        "# Select relevant AQI columns\n",
        "aqi_columns = [\"O3 AQI\", \"CO AQI\", \"SO2 AQI\", \"NO2 AQI\"]\n",
        "\n",
        "# Create a new column for overall AQI (maximum of all pollutants)\n",
        "aqi_df[\"Overall_AQI\"] = aqi_df[aqi_columns].max(axis=1)\n",
        "\n",
        "# Define AQI categories\n",
        "aqi_categories = {\n",
        "    \"Good\": (0, 50),\n",
        "    \"Moderate\": (51, 100),\n",
        "    \"Unhealthy for Sensitive Groups\": (101, 150),\n",
        "    \"Unhealthy\": (151, 200),\n",
        "    \"Very Unhealthy\": (201, 300),\n",
        "    \"Hazardous\": (301, float(\"inf\"))\n",
        "}\n",
        "\n",
        "# Function to classify AQI levels\n",
        "def categorize_aqi(aqi_value):\n",
        "    for category, (min_val, max_val) in aqi_categories.items():\n",
        "        if min_val <= aqi_value <= max_val:\n",
        "            return category\n",
        "    return \"Unknown\"\n",
        "\n",
        "# Apply AQI categorization\n",
        "aqi_df[\"AQI Category\"] = aqi_df[\"Overall_AQI\"].apply(categorize_aqi)\n",
        "\n",
        "# Check if population data is available\n",
        "if \"Population\" in aqi_df.columns:\n",
        "    # Group by AQI category and sum population exposure\n",
        "    aqi_exposure = aqi_df.groupby(\"AQI Category\")[\"Population\"].sum().reset_index()\n",
        "else:\n",
        "    # Count occurrences of each AQI category as a proxy for exposure\n",
        "    aqi_exposure = aqi_df[\"AQI Category\"].value_counts().reset_index()\n",
        "    aqi_exposure.columns = [\"AQI Category\", \"Exposure Count\"]\n",
        "\n",
        "# Save processed data to CSV\n",
        "aqi_exposure.to_csv(\"aqi_population_exposure.csv\", index=False)\n",
        "\n",
        "print(\"CSV file saved as aqi_population_exposure.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCtpth4rUsxq",
        "outputId": "75189574-4080-449d-d605-5941a8eef68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file saved as aqi_population_exposure.csv\n"
          ]
        }
      ]
    }
  ]
}